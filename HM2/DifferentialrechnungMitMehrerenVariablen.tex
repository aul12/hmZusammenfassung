%!TEX root = ../main.tex
\section{Der n-dimensionale Euklidische Raum}

\subsection{Definitionen}
Sind $n, m \in \N$, so gelten folgende Bezeichungen:
\begin{eqnarray*}
    \R^n &:=& \Bigg\{
        \begin{pmatrix}
            x_1\\
            \vdots \\
            x_n
        \end{pmatrix}
        \text{ für }
        x_1, \ldots, x_n \in \R
    \Bigg\} \\
    \R^{m \times n} &:=& \Bigg\{
        \begin{pmatrix}
            a_{11} & \cdots & a_{1n}\\
            \vdots & \ddots & \vdots \\
            a_{m1} & \cdots & a_{mn}
        \end{pmatrix}
        \text{ für }
        a_{ij} \in \R, 1 \leq i \leq m, 1 \leq j \leq n
    \Bigg\}\\
    <x, y> &:=& x \cdot y := x^T y := \sum_{k=1}^n x_k y_k \text{ (Skalarprodukt)}\\
    \norm{x} &:=& {\Vert x \Vert}_2 := \abs{x} := \sqrt{\sum_{k=1}^n x_k^2}
    \text{ euklidische Norm des }\R^n\text{/Betrag in }\R^n
\end{eqnarray*}

\subsection{Folgerungen}
\begin{enumerate}
    \item
        \begin{equation*}
            \norm{x}_\infty = \max_{k=1\ldots n} \abs{x_k}
            \leq \norm{x}_2 \leq \sqrt{n} \max_{k=1 \ldots n} \abs{x_k}
            \ \forall x \in \R^n
        \end{equation*}
    \item
        \begin{equation*}
            \norm{x}_1 = \sum_{k=1}^n \abs{x_k}
        \end{equation*}
        und
        \begin{equation*}
            \norm{x}_2 \leq \norm{x}_1
        \end{equation*}
    \item $\norm{x}_1$, $\norm{x}_2$, $\norm{x}_\infty$ sind drei mögliche Festlegungen
        für Vektornormen. Allgemein hat eine Norm $\norm{\cdot}$
        ($\norm{\cdot}: \R^n \rightarrow \R$) folgende Eigenschaften:
        \begin{eqnarray*}
            &\norm{x} \geq 0&\ \forall x \in \R^n \land \norm{x}=0 \Leftrightarrow
            x = \begin{pmatrix}
            0 \\ 0
            \end{pmatrix}
            = \vec{0} \\
            &\norm{\alpha \cdot x} = \abs{\alpha} \cdot \norm{x}&\ \forall \alpha
            \in \R\land \forall x \in \R^n \\
            &\norm{x + y} \leq \norm{x} + \norm{y}&\ \forall x, y \in \R^n
        \end{eqnarray*}
    \item Der Einheitskreis ist bezüglich verschiedener Normen nicht immer ein Kreis
    \item p-Norm:
        \begin{equation*}
            \norm{x}_p = \nthSqrt{p}{\sum_{k=1}^n \abs{x_k}^p}
        \end{equation*}
     \item $x \cdot y$ im $\R^2$ hat die anschauliche Bedeutung
        \begin{equation*}
            <x,y> = x \cdot y = \norm{x}_2 \cdot \norm{y}_2 \cdot \cos(\alpha)
        \end{equation*}
        Daraus folgt die Cauchy-Schwarzsche-Ungleichung (CSU)
        \begin{equation*}
            <x,y> \leq \norm{x}_2 \cdot \norm{y}_2
        \end{equation*}
\end{enumerate}

\subsection{Konventionen}
\begin{enumerate}[label= (\alph*)]
    \item In $\R^n$ sei stets $A^c := \R^n \backslash A$ für eine Menge $A \subseteq \R^n$
    \item Mit $\norm{\cdot}$ bezeichnen wir die euklidische Norm $\norm{\cdot}_2$.
    Außer es wird explizit gesagt, dass $\norm{\cdot}$ eine allgemeine Norm ist
    (z.B. \glqq{} Sei $\norm{\cdot}$ eine Norm   auf $\R^n$ \grqq{})
\end{enumerate}

\subsection{Definition Epsilon-Umgebung}
Sei $a \in \R^n, \varepsilon > 0$ dann heißt
\begin{eqnarray*}
    U_\varepsilon(a) &:=& \{ x \in \R^n |\ \norm{x-a} < \varepsilon \} \text{ die }
    \varepsilon \text{-Umgebung von }a\\
    \dot{U}_\varepsilon(a) &:=& U_\varepsilon(a) \backslash \{a \}
    \ \ ( =\{ x \in \R^n |\ 0<\norm{x-a}<\varepsilon \} ) \text{ die punktierte }
    \varepsilon \text{-Umgebung von }a
\end{eqnarray*}

\subsection{Definition Topologische Begriffe}
Sei $A \subseteq \R^n$. Ein Punkt $a \in \R^n$ heißt:
\begin{enumerate}[label= (\alph*)]
    \item Innerer Punkt von $A$, falls ein $\varepsilon > 0$ existiert, sodass
        $U_\varepsilon(a) \subseteq A$
        Kurz:
        \begin{equation*}
            a \text{ innerer Punkt von }A :\Leftrightarrow \exists \varepsilon>0
            : U_\varepsilon(a) \subseteq A
        \end{equation*}

        Die Menge $\overset{\circ}{A}$ ist die Menge aller innerer Punkte von $A$
        \begin{equation*}
            \overset{\circ}{A} := \{ a \in \R^n | \exists \varepsilon > 0 \text{ mit }
            U_\varepsilon(a) \subseteq A \}
        \end{equation*}
    \item Berührungspunkt von $A$, wenn jede $\varepsilon$-Umgebung von $a$ mindestens
        einen Punkt aus $A$ enthält.
        Kurz:
        \begin{equation*}
            a \in \R^n \text{ ist Berührpunkt von } A :\Leftrightarrow
            \forall \varepsilon>0: U_\varepsilon(a) \cap A \neq \emptyset
        \end{equation*}

        Die Menge aller Berührpunkte von
        \begin{equation*}
            \bar{A} := \{ x \in \R^n | \forall \varepsilon > 0 \text{ ist }
            U_\varepsilon(a) \cap A \neq \emptyset \}
        \end{equation*}
        heißt der Abschluss oder abgeschlossene Hülle von $A$.
    \item Häufungspunkt von $A$, wenn jede punktierte $\varepsilon$-Umgebung von
        $a$ ein Element von $A$ enthält.
        Kurz:
        \begin{equation*}
            a \in \R^n \text{ ist Häufungspunkt } :\Leftrightarrow
            \forall\ \varepsilon > 0:\ \dot{U}_\varepsilon(a) \cap A \neq \emptyset
        \end{equation*}
    \item Randpunkt von $A$, wenn jede $\varepsilon$-Umgebung Elemente aus $A$
        und $A^c$ enthält.
        Kurz:
        \begin{equation*}
            a \in \R^n \text{ ist Randpunkt von }A :\Leftrightarrow
            \forall \varepsilon > 0\
            (U_\varepsilon(a) \hat A \neq \emptyset) \land
            (U_\varepsilon(a) \hat A^c \neq \emptyset)
        \end{equation*}
        Die Menge
        \begin{equation*}
            \partial A := \{ a \in \R^n | a \text{ ist Randpunkt von }A \}
        \end{equation*}
        heißt der Rand von $A$.
\end{enumerate}

\subsubsection{Bemerkung}
Man kann zeigen:
\begin{equation*}
    \bar{A} = A \cup \partial A =  \overset{\circ}{A} \cup \partial A
\end{equation*}

\subsection{Definition offene und abgeschlossene Menge}
Eine Menge $A \subseteq \R^n$ heißt:
\begin{enumerate}[label= (\alph*)]
    \item offen, wenn $A = \overset{\circ}{A}$ gilt (also $A$ besteht nur aus
        innerern Punkten)
    \item abgeschlossen, wenn $\partial A \subseteq A$ (Rand gehört zu $A$)
\end{enumerate}

\section{Folgen}
\subsection{Definition}
Eine Folge
\begin{equation*}
    a_k =
    \begin{pmatrix}
        a_1^{(k)} \\
        \vdots \\
        a_n^{(k)}
    \end{pmatrix}
\end{equation*}
in $\R^n$ heißt:
\begin{enumerate}[label= (\alph*)]
    \item Konvegent gegen einen Grenzwert $a$, wenn gilt:
        \begin{equation*}
            \forall \varepsilon > 0\ \exists n(\varepsilon): \norm{a_k - a}<\varepsilon
            \ \forall k \geq n(\varepsilon)
        \end{equation*}
        Schreibweise:
        \begin{equation*}
            \lim_{k \rightarrow \infty} a_k = a \text{ oder }
            a_k \rightarrow a\ (k \rightarrow \infty)
        \end{equation*}
    \item Beschränkt, wenn gilt:
        \begin{equation*}
            \exists c > 0:\ \norm{a_k} < c\ \forall k \in \N
        \end{equation*}
\end{enumerate}

\subsubsection{Bemerkung}
\begin{enumerate}[label= (\alph*)]
    \item Die Norm $\norm{\cdot}$ sei hier die euklidische Norm $\norm{\cdot}_2$. Wir
        werden aber sehen: Jede Norm auf $\R^n$ wäre ok.
    \item
        \begin{equation*}
            a_k \rightarrow a\ (k \rightarrow \infty) \Rightarrow
            \text{ Jede Komponente von }a_k\text{ konvergiert gegen entsprechende
            Komponente von }a
        \end{equation*}
    \item Cauchy-Kriterium:
        \begin{equation*}
            {(a_k)}_{k=1}^\infty \text{ konv. } \Leftrightarrow \forall \varepsilon > 0\ \exists
            n(\varepsilon): \norm{a_k - a_l} < \varepsilon
            \forall k,l \geq n(\varepsilon)
        \end{equation*}
\end{enumerate}

\subsection{Bolzano-Weierstraß}
Jede beschränkte Folge im $\R^n$ hat eine konvergente Teilfolge.

\subsection{Grenzwertrechenregeln}
Die Grenzwertrechenregeln übertragen sich auch auf Folgen im $\R^n$.

\subsection{Weitere Bemerkungen}
Sei $A \subseteq  \R^n$ und $a \in \R^n$, dann gilt:
\begin{enumerate}[label= (\alph*)]
    \item
        \begin{equation*}
            a \in \bar{A} \Leftrightarrow \exists {(a_k)}_{k=1}^\infty
            \text{ mit } a_k \in A\ \forall k \text{ mit } \lim_{k \rightarrow \infty}
            a_k = a
        \end{equation*}
    \item $a$ ist ein Häufungspunkt von $A$
        \begin{equation*}
            \exists {(a_k)}_{k=1}^\infty \text{ mit } a_k \in A \backslash \{a\}
            \text{ mit } \lim_{k \rightarrow \infty} a_k = a
        \end{equation*}
    \item $A$ ist abgeschlossen $\Leftrightarrow$ für jede konvergente Folge
        ${(a_k)}_{k=1}^\infty$ mit $a_k \in A\ \forall k$ gilt
        $\lim\limits_{k \rightarrow \infty} a_k \in A$.
    \item $A$ ist kompakt $\Leftrightarrow$ Jede Folge in $A$ besitzt einen
        Häufungspunt in $A$.
\end{enumerate}

\section{Funktionsgrenzwerte und Stetigkeit}

\subsection{Definition Funktion}
Eine Funktione $f: A \subseteq \R^n \rightarrow \R^m$ nennt man eine Funktion in
$n$ Veränderlichen (oder Vektorfeld).
Im Fall $m=1$ nennt man $f$ eine reele Funktion (oder Skalarfeld).

\subsubsection{Schreibweise}
\begin{equation*}
    f(x_1, x_2, \ldots, x_n) :=
    f\left(\begin{pmatrix}
        x_1\\
        \vdots \\
        x_n
    \end{pmatrix} \right) :=
    \begin{pmatrix}
        f_1(x_1, \ldots, x_n)\\
        \vdots \\
        f_m(x_1, \ldots, x_n)
    \end{pmatrix}
\end{equation*}

\subsection{Definition Funktionsgrenzwert}
Sei $f: A \subseteq \R^n \rightarrow \R^m$ und $a \in \bar{A}$ dann heißt ein
$b \in \R^m$ mit:
\begin{equation*}
    \forall \varepsilon>0\ \exists \delta(\varepsilon):
    \norm{f(x) - b}<\varepsilon\
    \forall x \in \dot{U}_{\delta(\varepsilon)}(a) \cap A
\end{equation*}
der Grenzwert von $f$ für x gegen a. Kurz:
\begin{equation*}
    \lim_{x \rightarrow a} f(x) = b
\end{equation*}

\subsection{Definitionen aus HM 1 im Mehrdimensionalen}
Sei $f: A \subseteq \R^n \rightarrow \R^m$, $a \in \bar{A}$ und $b \in \R^m$
\begin{enumerate}[label= (\alph*)]
    \item Folgende Aussagen sind äquivalent:
        \begin{enumerate}
            \item $f(x) \rightarrow  b\ (x \rightarrow a)$
            \item $\norm{f(x) - b} \rightarrow 0\ (x \rightarrow a, x \in A)$
            \item Für jede Komponente
                \begin{equation*}
                    f_l(x) \text{ von } f(x) =
                    \begin{pmatrix}
                        f_1(x)\\
                        \vdots \\
                        f_m(x)
                    \end{pmatrix}
                    \text{ gilt }
                    f_l(x) \rightarrow b_l\ (x \rightarrow a)
                \end{equation*}
            \item Für eine Folge ${(x_k)}_{k=1}^\infty$ in A mit
                $\lim\limits_{k \rightarrow \infty}$ und $x_k \neq a\ \forall k$ folgt:
                \begin{equation*}
                        f(x_k) \rightarrow b\ (k \rightarrow \infty)
                \end{equation*}
        \end{enumerate}
    \item Falls $\lim\limits_{x \rightarrow a} f(x)$ existiert ist dieser
        Eindeutig.
    \item Cauchy-Kriterium:
        \begin{equation*}
            \forall \varepsilon > 0\ \exists \delta(\varepsilon):
            \norm{f(x) -f(y)}<\varepsilon\ \forall x,y \in
            \dot{U}_{\delta{\varepsilon}}(a) \cap A
        \end{equation*}
    \item Grenzwertrechenregeln gelten analog zu HM 1
    \item Sei $B \subseteq A$ mit $a \in \bar{B}$ dann gilt:
        \begin{equation*}
            \lim_{x \rightarrow a \text{ mit } x \in B} f(x) = b \Leftrightarrow
            \lim_{x \rightarrow a \text{ mit } x \in A} f(x) = b
        \end{equation*}
\end{enumerate}

\subsection{Definition Stetigkeit}
Sei $f: A \subseteq \R^n \rightarrow \R^m$ und $a \in A$, dann ist $f$ in $a$
stetig wenn gilt $\lim\limits_{x \rightarrow a} f(x) = f(a)$. Das heißt:
\begin{equation*}
    \forall\varepsilon\ \exists \delta(\varepsilon):
    \norm{f(x) - f(a)} < \varepsilon\ \forall x \in U_{\delta(\varepsilon)}(a)
    \cap A
\end{equation*}

\subsection{Grenzwerte von verketteten Funktionen}
Sei $A \subseteq \R^n, B \subseteq \R^m, a \in \bar{A}$ und $f: A \rightarrow B,
g: B \rightarrow \R^l$. Existiert $\lim\limits_{x \rightarrow a} f(x) = b$ so
gilt $b \in \bar{B}$ und es gilt:
\begin{equation*}
    \lim_{x \rightarrow a} g(f(x)) = \lim_{y \rightarrow b} g(y)
\end{equation*}
sofern der Grenzwert $\lim\limits_{y \rightarrow b} g(y)$ existiert.

\subsection{Grenzwertrechenregeln}
Für $f, g: A \rightarrow \R^n$ gilt: Falls $\lim\limits_{x \rightarrow a} f(x)
= \alpha$ und $\lim\limits_{x \rightarrow a} g(x) = \beta$ existiert, dann gilt:
\begin{enumerate}[label= (\alph*)]
    \item
        \begin{equation*}
            \lim_{x \rightarrow a} f(x) + g(x) = \alpha + \beta
        \end{equation*}
    \item
        \begin{equation*}
            \lim_{x \rightarrow a} {f(x)}^T g(x) = \alpha^T \beta
        \end{equation*}
\end{enumerate}

\subsection{Maximum und Minimum Kompakter Mengen}
\begin{enumerate}[label= (\alph*)]
    \item Ist $\emptyset \neq A \subseteq \R$ kompakt, so existiert $\max{A}$ und
        $\min{A}$.
    \item Ist $A \subseteq \R^n$, $A$ kompakt und $f: \R^m \rightarrow \R^n$
        stetig auf $A$, dann ist $f(A)$ kompakt.
\end{enumerate}

\subsection{Weierstraß}
Falls $A \subseteq \R^m$ und $f: A \rightarrow \R$ stetig ist dann gilt:
\begin{equation*}
    A \text{ kompakt } \Rightarrow \min_{x \in A} f(x), \max_{x \in A} f(x)
    \text{ existiert}
\end{equation*}


\section{Partielle Ableitungen und Richtungsableitungen}
\subsection{Definition partielle Ableitung}
Eine Funktion $f: A \subseteq \R^m \rightarrow \R^n$ heißt in einem Punkt
$a \in \R^m$ partiell differentierbar nach seiner $k$-ten Variable $x_k
(k \in \{ 1, \ldots, m\})$ wenn $f(a + h \cdot e_k)$ mit
\begin{equation*}
    e_k = \begin{pmatrix}
        0 \\ 0 \\ \vdots \\ 1\ (k\text{-te Komponente}) \\ \vdots \\ 0
    \end{pmatrix}
\end{equation*}
für ein festes $\delta > 0$ und alle $h$ mit $\abs{h} < \delta$ existiert:
\begin{equation*}
    \frac{\partial}{\partial x_k} f(a) := f_{x_k} (a) :=
    \lim_{h \rightarrow 0} \frac{f(a + h \cdot e_k) - f(a)}{h}
\end{equation*}

Dieser Grenzwert heißt partielle Ableitung von $f$ nach $x_k$ bei $a$.

\vspace{0.5cm}

Exisitiert bei $a$ die partiellen Ableitungen $f_{x_1}(a), \ldots, f_{x_m}(a)$
so heißt $f$ (einmal) partiell differentierbar bei $a$ und nennt man im Fall $n=1$
den Spaltenvektor
\begin{equation*}
    \nabla f(a) := \grad f(a) :=
    \begin{pmatrix}
        f_{x_1}(a) \\ \vdots \\ f_{x_m}(a)
    \end{pmatrix}
\end{equation*}
den Gradienten von $f$ bei $a$.

Falls alle partiellen Ableitungen stetig sind nennt man $f$ stetig partiell
differentierbar.

\subsubsection{Schreibweise}
\begin{equation*}
    C^k(G, \R^n) := \{ f: G \rightarrow \R^n \vert \text{ alle } k \text{-ten
    partiellen Ableitungen existieren und sind stetig} \}
\end{equation*}

\subsection{Definition Umgebung eines Punktes}
Eine Umgebung eines Punktes $a \in \R^n$ ist eine Menge $U \subseteq \R^n$ für
die ein $\varepsilon > 0$ existiert, so dass $U_\varepsilon (a) \subseteq U$.
Eine offene Umgebung $U$ ist eine Umgebung, die zusätzlich eine offene Menge ist.

\subsubsection{Bemerkung}
Ist $f: G \subseteq \R^n \rightarrow \R$ partiell differentierbar und sind in einer
Umgebung von $a \in G$ alle partiellen Ableitungen beschränkt, dann ist $f$ stetig
in $a$.

\subsection{Definition Richtungsableitung}
Seien $a, r \in \R^n$ und $r$ eine Richtung, d.h. $\norm{r} = 1$. Eine Funktion
$f: G \subseteq \R^n \rightarrow \R^m$ heißt bei $a$ in Richtung $r$ differentierbar,
wenn der Grenzwert
\begin{equation*}
    \frac{\partial}{\partial r} f(a) := \lim_{h \rightarrow 0}
    \frac{f(a + h \cdot r) - f(a)}{h}
\end{equation*}
existiert. Dieser Grenzwert heißt dann die Richtungsableitung von $f$ bei $a$ in
Richtung $r$.

\section{Die totale Ableitung}

\subsection{Definition totale Ableitung}
Sei $f: G \subseteq \R^n \rightarrow \R^m$ und $a \in G \subseteq \R^n$
\begin{enumerate}[label= (\alph*)]
    \item
        Man nennt $f$ total differentierbar bei $a$, wenn es eine Matrix $A \in
        R^{m \times n}$ gibt, dass bei einer Umgebung $U$ von $a$ gilt:
        \begin{equation*}
            f(x) = f(a) + A(x-a) + r(x)
        \end{equation*}
        mit
        \begin{equation*}
            \frac{r(x)}{\norm{x-a}} \rightarrow \vec{0}\ (x \rightarrow a)
        \end{equation*}
        In dem Fall nennen wir $A$ die (totale) Ableitung von $f$ bei $a$ und wir
        schreiben $f'(a) = A$
    \item Ist   $f = \begin{pmatrix}f_1\\ \vdots \\ f_n\end{pmatrix}$ partiell
        differentierbar bei $a$, so heißt
        \begin{equation*}
            \begin{pmatrix}
                \frac{\partial}{\partial x_1} f_1(a) & \cdots & \frac{\partial}{\partial x_n} f_1(a)\\
                \vdots & \ddots & \vdots \\
                \frac{\partial}{\partial x_1} f_m(a) & \cdots & \frac{\partial}{\partial x_n} f_m(a)\\
            \end{pmatrix}
            =
            \begin{pmatrix}
                \nabla {f_1(a)}^T \\ \vdots \\ \nabla {f_n(a)}^T
            \end{pmatrix}
            = \frac{\partial}{\partial x}f(a) = J_f(a)
        \end{equation*}
        die Jacobi-Matrix von $f$ bei $a$.
\end{enumerate}

\subsubsection{Bemerkung}
\begin{enumerate}[label= (\alph*)]
    \item Wir werden sehen, dass gilt:
        \begin{equation*}
            f \text{ ist in }a\text{ total differentierbar} \Leftrightarrow
            f'(a) = J_f(a)
        \end{equation*}
    \item Im Fall $m=1$ gilt also:
        \begin{equation*}
            J_f(a) = \nabla {f(a)}^T
        \end{equation*}
        und falls $f$ total differentierbar ist gilt:
        \begin{equation*}
            f'(a) = \nabla {f(a)}^T
        \end{equation*}
    \item Bedeutung des Skalarprodukts $x,y \in \R^n$
        \begin{equation*}
            x \cdot y := x^T y := \sum_{k=1}^n x_k y_k = \norm{x}_2 \norm{y}_2
            \cos{\alpha}
        \end{equation*}
    \item Definition des Matrix-Vektor-Produktes:
        \begin{eqnarray*}
            &A \in \R^{m \times n}, x \in \R^n, b \in \R^m&\\
            &A \cdot x =
            \begin{pmatrix}
                a_{11} & \cdots & a_{1n}\\
                \vdots & \ddots  & \vdots \\
                a_{m1} & \cdots & a_{mn}
            \end{pmatrix}
            \begin{pmatrix}
                x_1 \\ \vdots \\ x_n
            \end{pmatrix}
            =
            \begin{pmatrix}
                a_{11} x_1 + \cdots + a_{1n} x_n\\
                \vdots \\
                a_{m1} x_1 + \cdots + a_{mn} x_n
            \end{pmatrix}&
        \end{eqnarray*}
\end{enumerate}

\subsection{Zusammenhang Stetigkeit und Differenzierbarkeit}
Ist $f: G \subseteq \R^n \rightarrow \R^m$ differentierbar in $a \in G$
$\Rightarrow f$ stetig in $a$.

\subsection{Zusammenhang partielle und totale Diffbarkeit}
Sei $f: G \subseteq \R^n \rightarrow \R^m$ und $a \in G$
\begin{enumerate}[label= (\alph*)]
    \item Ist $f$ total differentierbar bei $a$, so gilt:
        \begin{enumerate}[label= (\alph*)]
            \item $f$ ist bei $a$ partiell differentierbar und
                \begin{equation*}
                    f'(a) = \frac{\partial}{\partial x} f(a)
                \end{equation*}
            \item $f$ ist bei $a$ in jede Richtung $r$ differentierbar und
                \begin{equation*}
                    \frac{\partial}{\partial r} f(a) = J_f(a) \cdot r
                \end{equation*}
        \end{enumerate}
    \item Wenn $f$ partiell differentierbar in $a$ ist und alle partiellen
        Ableitungen in $a$ stetig sind, so ist $f$ in $a$ differentierbar.
        \begin{equation*}
            \frac{\partial}{\partial x_n} f(x_n) \text{ stetig in }a
            \Leftrightarrow f \text{ differenzierbar in }a
        \end{equation*}
\end{enumerate}

\subsection{Kettenregel}
Ist $f: A \subseteq \R^n \rightarrow B \subseteq \R^m$ total differentierbar in
$a \in A$ und $g: B \rightarrow R^l$ total differentierbar in $a$. Dann gilt
$g \circ f$ ist in $a$ differentierbar und
\begin{equation*}
    {(g \circ f)}' = g'(f(a)) \cdot f'(a)
\end{equation*}

\subsection{Matrix-Produkt}
Für $A \in \R^{m \times k}, B \in \R^{k \times n}$ und $C \in \R^{m \times n}$
ist das Matrix-Produkt $C = A \cdot B$ definiert durch:
\begin{equation*}
    c_{ij} = \sum_{l=1}^k a_{il} b_{lj}
\end{equation*}

\section{Extremwerte, Mittelwertsatz}

\subsection{Definition lokales Extrema}
\begin{enumerate}[label= (\alph*)]
    \item Eine Funktion $f: G \subseteq \R^n \rightarrow \R$ besitzt in $x_0 \in G$ ein
        lokales Minimum (bzw. Maximum), wenn in einer Umgebung von $U$ von $x_0$ gilt:
        \begin{equation*}
            f(x) \geq  f(x_0)\ (\text{bzw. } f(x) \leq f(x_0))\ \forall x \in U
        \end{equation*}
        unter einem lokalen Extrema versteht man ein lokales Minimum oder Maximum
    \item $f$ besitzt in $x_0$ ein globales Minimum (bzw. Maximum), wenn
        \begin{equation*}
            f(x) \geq f(x_0)\ (\text{bzw. } f(x) \leq f(x_0))\ \forall x \in G
        \end{equation*}
\end{enumerate}

\subsection{Notwendige Bedingung für lokale Extrema}
Besitzt $f: G \subseteq \R^n \rightarrow \R, f \in C^1(G, \R)$ in
$x_0 \in \overset{\circ}{G}$ ein lokales Extrema, so gilt:
\begin{equation*}
    \nabla f(x_0) = 0
\end{equation*}

\subsubsection{Bemerkung}
Einen Punkt $x_0 \in G$ mit $\nabla f(x_0) = 0$ nennen wir kritischen Punkt oder
stationären Punkt.

\subsection{Mittelwertsatz}
Sei $f: G \subseteq \R^n \rightarrow \R$ mit $G$ offen differentierbar und $G$
enthalte die Menge
\begin{equation*}
    L(a, b) :=\overline{ab} := \{ a + t \cdot (b-a)\ \vert t \in [0,1] \}
\end{equation*}

für $a,b \in G$. Dann exisitiert ein $\xi \in (0,1)$ mit
\begin{equation*}
    f(b) = f(a) + {\nabla f(a + \xi (b-a))}^T (b-a)
\end{equation*}

\subsection{Gebiete bzw.\ kurvenweise zusammenhängende Gebiete}
\begin{enumerate}[label= (\alph*)]
    \item Eine Menge
        \begin{equation*}
            \overline{a_0, a_1, \ldots, a_n} := \bigcup_{k=0}^{n-1} \overline{a_k, a_{k+1}}
        \end{equation*}
        für $a_0, \ldots, a_n \in \R^m$ heißt Polygonzug
    \item Eine Menge $M \subseteq \R^n$ heißt kurvenweise zuammenhängend, wenn zu
        $a, b \in M$ stets eine stetige Funktion $\gamma: [0,1] \rightarrow M$
        exisitiert mit $\gamma(0) = a$ und $\gamma(1) = b$ (dann ist $\gamma$)
        eine Kurve von $a$ nach $b$.
    \item Eine Menge $G \subseteq \R^n$ heißt Gebiet, wenn $G$ offen und
        kurvenweise zusammenhängend ist (keine Inseln).
\end{enumerate}

\subsubsection{Bemerkung}
Ist $G$ ein Gebiet und $a, b \in G$ dann existiert stets ein Polynomzug, der $a$
und $b$ verbindet und durch $G$ verläuft.


\subsection{Partielle Ableitung r-ter Ordnung}
Für $f: G \subseteq \R^n \rightarrow \R^m$ definiert man (falls existent) für
$x_0 \in G$ und $k_1, \ldots, k_r \in \{ 1, \ldots, n \}$ die partielle Ableitung
$r$-ter Ordnung indirekt durch:
\begin{equation*}
    \frac{\partial^r}{\partial x_{k_1} \ldots \partial x_{k_r}} f(x_0) :=
    f_{x_{k_1} \cdots x_{k_r}} (x_0) :=
    \begin{cases}
        \dfrac{\partial}{\partial x_{k_1}} f(x_0) & \text{falls } r=1\\
        \dfrac{\partial}{\partial x_{k_1}} \left(
        \dfrac{\partial^{r-1}}{\partial x_{k_2} \ldots \partial x_{k_r}} f(x_0)
        \right) & \text{sonst}
    \end{cases}
\end{equation*}
existieren alle partiellen Ableitungen der Ordnung $r$, dann ist $f$ $r$-mal
partiell differentierbar sind diese außerdem stetig, so ist $f$ $r$-mal stetig
partiell differentierbar.

\subsubsection{Schreibweise}
\begin{equation*}
    C^r(G, \R^m) := \{ f: G \rightarrow \R^m\ \vert \ f\ r\text{-mal stetig
    partiell differentierbar}\}\text{ und }
    C^r(G) := C^r(G, \R^1)
\end{equation*}

\subsection{Hessematrix}
Ist $f: G \subseteq \R^n \rightarrow \R$ 2-mal partiell differentierbar bei
$a \in G$ so heißt
\begin{equation*}
    H_f(a) :=
    \begin{pmatrix}
        f_{x_1 x_1}(a) & \cdots & f_{x_1 x_n}(a)\\
        \vdots & \ddots & \vdots \\
        f_{x_n x_1}(a) & \cdots & f_{x_n x_n}(a) \\
    \end{pmatrix}
    =
    \begin{pmatrix}
        \nabla f_{x_1}(a) & \cdots & \nabla f_{x_n}(a)
    \end{pmatrix}
\end{equation*}
die Hesse-Matrix von $f$ bei $a$.

\subsection{Definitheit}
Sei $A \in \R^{n \times n}$
\begin{enumerate}[label= (\alph*)]
    \item Die durch $Q_A(x) := x^T \cdot A \cdot x$ definierte Funktion
        $Q_A: \R^n \rightarrow \R$ heißt die Quadratische Form von $A$.
    \item Die Matrix und die Quadratische Form heißen:
        \begin{enumerate}
            \item positiv definit
                \begin{equation*}
                    :\Leftrightarrow Q_A(x) > 0\ \forall x \in \R^n \backslash \{ 0 \}
                \end{equation*}
            \item positiv semidefinit
                \begin{equation*}
                    :\Leftrightarrow Q_A(x) \geq 0\ \forall x \in \R^n
                \end{equation*}
            \item negativ definit
                \begin{equation*}
                    :\Leftrightarrow Q_A(x) < 0\ \forall x \in \R^n \backslash \{ 0 \}
                \end{equation*}
            \item negativ semidefinit
                \begin{equation*}
                    :\Leftrightarrow Q_A(x) \leq 0\ \forall x \in \R^n
                \end{equation*}
            \item indefinit
                \begin{equation*}
                    :\Leftrightarrow \exists x, y \in \R^n:\ Q_A(x) < 0, Q_A(y) > 0
                \end{equation*}
        \end{enumerate}
\end{enumerate}

\subsection{Satz von Schwarz}
Ist $G \neq \emptyset, f: G \subseteq \R^n \rightarrow \R$ 2-mal stetig partiell
differentierbar, dann gilt:
\begin{equation*}
    H_f(x, y) = {H_f(x,y)}^T
\end{equation*}

\subsection{Satz von Taylor}
Seien $a, b \in G$ ($G$ eine Gebiet mit $G \neq \emptyset$), $f: G \subseteq \R^n
\rightarrow \R$ zweimal stetig differentierbar und $\overline{ab} \subseteq G$.
Dann existiert eine $\xi \in (0,1)$ mit
\begin{equation*}
    f(b) = f(a) + \nabla {f(a)}^T (b-a) + \frac{1}{2} {(b-a)}^T H_f(a+ \xi (b-a))
    (b-a)
\end{equation*}

\subsection{Hinreichende Bedinung für lokale Extrema}
Sei $f \in C^2(U, \R)$ mit $U$ eine Umgebung von $a$ und $\nabla f(a) = \vec{0}$
dann gilt:
\begin{enumerate}[label= (\alph*)]
    \item Ist $H_f(a)$ positiv definit, so ist bei $a$ ein lokales Minimum
    \item Ist $H_f(a)$ negativ definit, so ist bei $a$ ein lokales Maximum
\end{enumerate}

\section{Implizit definierte Funktionen}
\subsection{Bemerkung}
Wir betrachten zunächst lineare Funktionen $f: \R^n \rightarrow \R^m$ dann lässt
sich  $f(x)$ darstellen als:
\begin{equation*}
    f(x) = A x + b
\end{equation*}
mit $A \in \R^{m \times n}, b \in \R^m$

\subsection{Vorläufige Definition Rang einer Matrix}
Wir definieren für eine Matrix $A \in \R^{m \times n}$ den Rang vorläufig als
die Anzahl der Stufen nachdem mit dem Gauss-Algorithmus die Matrix in
Zeilen-Stufenform überführt wurde.

\subsubsection{Bemerkung}
Allgemein werden wir sehen, dass $A x = b$ lösbar ist $\Leftrightarrow$ Rang von
$A$ gleich Rang von $(A \vert b)$ gilt. Eindeutig lösbar ist das LGS wenn in der
Zeilen-Stufen Form in jeder Zeile eine Stufe anfängt und $A$ quadratisch ist.

\subsection{Einheitsmatrix und Inverse eine Matrix}
Ist $A \in \R^{n \times n}$ und $B \in \R^{n \times n}$ mit
\begin{equation*}
    B \cdot A =
    \begin{pmatrix}
        1 & 0 & \cdots & 0 & 0\\
        0 & 1 & \cdots & 0 & 0\\
        \vdots & \ddots \\
        0 & 0 & \cdots & 0 & 1\\
    \end{pmatrix}
    I \text{ (Einheitsmatrix)}
\end{equation*}
dann nennt man $B$ die zu $A$ inverse Matrix und schreibt $A^{-1} := B$.
Dann gilt:
\begin{eqnarray*}
    A x &=& b \\
    \Leftrightarrow A^{-1} \cdot A \cdot x &=& A^{-1} \cdot b\\
    \Leftrightarrow I \cdot x &=& A^{-1} \cdot b\\
    \Leftrightarrow x &=& A^{-1} \cdot b
\end{eqnarray*}

Falls zu einer Matrix $A \in \R^{n \times n}$ die Inverse $A^{-1}$ existiert
nennt man $A$ regulär.

\subsubsection{Bemerkung}
Die Menge $G := \{ A \in \R^n: A \text{ ist regulär} \}$ ist bezüglich der
Matrixmultiplikation eine nicht abelsche Gruppe mit $I$ als neutrales Element
und $A^{-1}$ als das zu $A$ (links-) inverse Element.

\subsection{Zusammenhang Bijektivität und reguläre Matrizen}
Für $f: \R^n \rightarrow \R^n$ mit $f(x) = A \cdot x + b$ gilt:
\begin{equation*}
    f \text{ ist bijektiv } \Leftrightarrow A \text{ ist regulär}
\end{equation*}

\subsection{Satz über die Umkehrfunktion}
Sei $f \in C^1(G, \R^n)$ für ein Gebiet $G \subseteq \R^n$ und $x_0 \in G$. Weiter
gelte, dass $f'(x_0)$ regulär ist. Dann gibt es eine offene Umgebung $U$ von $x_0$
($U \subseteq G$), dass gilt:
\begin{enumerate}[label= (\alph*)]
    \item $f(U)$ ist offen und $f'(x)$ ist regulär
    \item $f: U \rightarrow V$ ist bijektiv und $f^{-1}: V \rightarrow U$ ist aus
        $C^1(V, U)$
    \item
        \begin{equation*}
            \frac{\text{d}}{\text{d}y} f^{-1} (y) = {(f'(f^{-1}(y)))}^{-1}
            \ \forall y \in V
        \end{equation*}
\end{enumerate}

\subsection{Satz über die Gebietstreue}
Ist $G$ eine offene Menge in $\R^n$ und $f \in C^1 (G, \R^n)$ mit $f'(x)$
ist regulär auf $G$, so ist auch $f(G)$ ein Gebiet.

\subsection{Definition Auflösbarkeit}
Sei $g: \R^{m + n} \rightarrow \R^m\ (n, m \in \N)$ und $b \in \R^m$.
Man nennt die Gleichung
\begin{equation*}
    g(x,y) = b \text{ mit } x \in \R^n \text{ und } y \in \R^m
\end{equation*}
\begin{enumerate}[label= (\alph*)]
    \item Auf $G \in \R^n$ (global) nach $y$ auflösbar, wenn es eine Funktion
        $f: G \subseteq \R^n \rightarrow \R^m$ gibt mit
        $g(x, f(x)) = b\ \forall x \in G$
    \item Bei $x_0 \in \R^n$ lokal nach $y$ auflösbar, wenn $g(x, y) = b$ in
        einer Umgebung von $x_0$ nach $y$ (global) auflösbar ist.

        D.h mit $y_0 := f(x_0)$ existiert die Auflösung $y = f(x)$ mit
        $g(x, f(x))=b$ und $y_0 = f(x_0)$ in einer Umgebung von $x_0$.
\end{enumerate}

\subsubsection{Bemerkung}
Allgemein soll auch für nichtlineare Funktionen einfach geprüft werden können ob
eine lokale Auflösung nach $x$ oder $y$ existiert.

Wir werden sehen es gilt:
\begin{equation}
    \frac{\partial}{\partial x} g \vert_{x=x_0} \text{ regulär } \Leftrightarrow
    \text{ Es existiert eine lokale Auflösung nach }x
\end{equation}
(Analog für Auflösungen nach $y$).

\subsection{Hauptsatz über implizite Funktionen}
Sei $x_0 \in \R^n$ und $y_0, b \in \R^m$. Für eine offene Umgebung $G$ von
$\left(\begin{smallmatrix}x_0\\y_0\end{smallmatrix}\right)$. Sei $g \in C^1(G, \R^m)$
(d.h $g: G \subseteq \R^{m + n} \rightarrow \R^m$ und stetig differentierbar) ist
$g(x_0, y_0)=b$ und $\frac{\partial}{\partial y} g(x_0, y_0)$ regulär, so gibt
es eine Umgebung $U$ von $x_0$ und $V$ von $y_0$, so dass:
\begin{enumerate}[label= (\alph*)]
    \item
        \begin{equation*}
            \frac{\partial}{\partial y} g(x, y) \text{ ist regulär }
            \forall x \in U \text{ und } \forall y \in V
        \end{equation*}
    \item Die Gleichung $g(x,y)=b$ besitzt eine eindeutige Auflösung
        $f: U \rightarrow V$ mit $y_0 = f(x_0)$ und es gilt:
        \begin{equation*}
            f'(x) = {(\frac{\partial}{\partial y} g(x, f(x)) )}^{-1} \cdot
            \frac{\partial}{\partial x} g(x, f(x)) \forall x \in U
        \end{equation*}
        (die Auflösung ist also differentierbar)
    \item Ist $g \in C^r (g, \R^m)$ dann ist $f \in C^r(U, \R^m)$
\end{enumerate}

\subsection{Extrema unter Nebenbedingungen}
\begin{equation*}
    \begin{cases}
        x+y & \rightarrow \max \text{oder } \min \\
        x^2 + y^2 = 1
    \end{cases}
\end{equation*}
\paragraph{Idee}
Nebenbedingung nach $y$ auflösen und in Zielfunktion einsetzten
\begin{enumerate}
    \item $y = \pm \sqrt{1-x^2}$
        \begin{equation}
            \Rightarrow f(x,y) = f(x, \pm \sqrt{1-x^2}) = \tilde{f}(x)
        \end{equation}
    \item
        \begin{equation*}
            \tilde{f}(x) \stackrel{!}{=}, \tilde{f}^{(k)}(x) \stackrel{!}{=}, \ldots,
                \tilde{f}^{2l}(x) \stackrel{!}{=} 0\ k=1,\ldots, 2\cdot l - 1
        \end{equation*}
\end{enumerate}

\paragraph{Beobachtung}
Bei den gesuchten Extrema berühren sich die Höhenlinien von $f$ und $g$
\begin{equation*}
    \stackrel{\text{Formaler}}{\Rightarrow} \exists \lambda \in \R:
    \nabla f(x,y) = \lambda \nabla g(x,y)
\end{equation*}
Aber die Bedingung ist ist nicht hinreichend, sondern nur notwendig.

Trotzdem: Die notwendige Bedingung liefert (hoffentlich) einen Endliche Anzahl
Kandidaten, diese können einzeln überprüft werden.

\subsection{Definition lokale Minima/Maxima unter Nebenbedingungen}
Seien $f, g_1, \ldots g_m: G \subseteq \R^n \rightarrow \R$ mit $G$ offen
gegeben sowie $b_1, \ldots, b_m \in \R$. Dann nennt man ein $x_0 \in G$ ein
lokales Minimum (bzw. Maximum) von $f$ unter der Nebenbedingung $g_1(x) = b_1
\ldots g_m(x) = b_m$ wenn es eine offene Umgebung $U \subseteq G$ von $x_0$ gibt
mit $f(x) \geq f(x_0) \forall x \in U$  und $g_k(x) = b_k$ für $k=1 \ldots m$
(bzw. $f(x) \leq f(x_0)  \forall x \in U$).

\subsection{Definition Linear Unabhängig}
Seien $a_1, \ldots, a_m \in \R^n$ mit $m\in \N$. Dann heißen diese Vektoren
linear unabhängig, wenn das lineare Gleichungssystem
\begin{equation*}
    \alpha_1 a_1 + \cdots + \alpha_n a_n = \vec{0}
\end{equation*}
nur die Lösung $\alpha_1 = \cdots \alpha_m = 0$ besitzt.
\begin{equation*}
    \Leftrightarrow
        \begin{pmatrix}
            a_1 & \ldots & a_m
        \end{pmatrix}
        \cdot
        \begin{pmatrix}
            \alpha_1 \\
            \vdots \\
            \alpha_n
        \end{pmatrix}
        =
        \begin{pmatrix}
            0 \\
            \vdots \\
            0
        \end{pmatrix}
\end{equation*}
Ansonsten sind die Vektoren linear abhängig.

\subsubsection{Bemerkung}
Sind $a_1, \cdots a_k$ nicht linear abhängig:
\begin{eqnarray*}
    \stackrel{\text{Def.}}{\Rightarrow} \exists\ k \in \{1, \ldots m\} \text{ und
    Lösung } \alpha_1, \ldots \alpha_m \text{ mit}\\
    \alpha_1 a_1 + \cdots + \alpha_k a_k + \ldots \alpha_m a_m = 0\ a_k \neq 0\\
    \Rightarrow a_k = -\frac{\alpha_1}{\alpha_k} a_1 \ldots -\frac{\alpha_1}{\alpha_k} a_{k-1}
    -\frac{\alpha_1}{\alpha_k} a_{k+1} \ldots
\end{eqnarray*}
d.h. $a_k$ lässt sich aus durch $a_1, \ldots, a_{k-1}, a_{k+1}, \ldots, a_m$
bestimmen.

\subsection{Satz von Lagrange}
Seien $f, g_1, \ldots g_m \in C^1(U)$ für eine offene Umgebung $U$ von $x_0 \in \R$
(wie oben $f,g_1 \ldots : G \subseteq \R^n \rightarrow \R$) und seien
$b_1, \ldots b_m \in \R$. Ist $x_0$ ein lokales Extrema unter der Nebenbedinung
$g_k(x) = b_k k=1,\ldots m$ und die Vektoren $\nabla g_1(x_0), \ldots \nabla g_m(x_0)$
linear unabhängig.
\begin{eqnarray*}
    \exists\  \lambda_1, \ldots, \lambda_m \in \R &\text{ mit }&
    \nabla f(x_0) + \lambda_1 \nabla g_1(x_0) + \cdots + \lambda_m \nabla g(x_0)
    = \vec{0} \\
    &\Leftrightarrow& f'(x_0)^T + J_g(x_0)^T \cdot \lambda = \vec{0} \\
    &\Leftrightarrow& f'(x_0) = \lambda^T J_g(x_0)
\end{eqnarray*}
Zudem muss $x_0$ die Nebenbedingung erfüllen.

\subsection{Lagrange Funktion}
\begin{eqnarray*}
    L(x,\lambda) &=& L(x_1, \cdots, x_m, \lambda_1, \cdots, \lambda_m)
    := f(x) + \lambda^T (g(x) - b) \\
    \Leftrightarrow L'(x,\lambda) &=& \left( f'(x) + \lambda^T g'(x), g(x)-b \right)
    \stackrel{!}{=} \vec{0}
\end{eqnarray*}
