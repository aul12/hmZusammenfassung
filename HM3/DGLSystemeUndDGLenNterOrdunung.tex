%!TEX root = ../main.tex
\section{Systeme von DGLen 1. Ordnung}
\subsection{Definition DGL-System}
Sei $G \subseteq \R^{n+1}$ und für $k \in \{1, \ldots, n\}$ sei $f_k: G \to \R$ stetig:
\begin{enumerate}[label= (\alph*)]
	\item $y(x) = (y_1(x), \ldots, y_n(x))^T$ heißt Lösung des Systems:
		\begin{eqnarray*}
			y_1' &=& f_1(x, y_1, \ldots, y_n) \\
			&\vdots& \\
			y_n' &=& f_n(x, y_1, \ldots, y_n) \\
		\end{eqnarray*}
		von DLGen $n$-ter Ordnung, wenn gilt:
		\begin{enumerate}
			\item 
				\begin{equation*}
					\begin{pmatrix}
						x \\ y(x)
					\end{pmatrix} \in G\ \forall x \in I
				\end{equation*} 
			\item $y$ ist differentierbar auf $I$ (Komponentenweise, d.h. $y_k$ ist diff'bar $\forall k$)
			\item $y_k'(x) = f_k(x, y_1(x), \ldots, y_n(x))\ \forall x \in I$ und bel. $k\in\{1, \ldots, n\}$ 
		\end{enumerate}
	\item Ist $(x,y)^T = (x_0, y_1^{(0)}, \ldots, y_n^{(0)})^T \in G$ dann löst $y: I \to \R^n$ das AWP.
		\begin{equation*}
			\text{(AWP)} = 
			\begin{cases}
				y_1'(x) &= f_1(x, y_1(x), \ldots, y_n(x)) \\
				&\vdots \\
				y_n'(x) &= f_n(x, y_1(x), \ldots, y_n(x))\\
				y_k(x_0) &= y_k^{(0)}\ k \in \{1, \ldots, n\}
			\end{cases}
		\end{equation*} 
		wenn $y$ die DGL löst und $y(x_0)=(y_1^{(0)}, \ldots,y_n^{(0)})^T$ gilt.
\end{enumerate}

\subsection{Schreibweise}
\begin{enumerate}[label= (\alph*)]
	\item DGL:
		\begin{enumerate}
			\item 
				\begin{equation*}
					y: I \to \R^n, y(x) := \begin{pmatrix}
						y_1(x) \\ \vdots \\ y_n(x)
					\end{pmatrix} \text{ oder }
					y = \begin{pmatrix}
						y_1 \\ \vdots \\ y_n
					\end{pmatrix}
				\end{equation*}
			\item
				\begin{equation*}
					f_k(x,y) = f_k(x, y_1, \ldots, y_n) \text{ bzw. }
					f_k(x,y(x)) = f_k(x, y_1(x), \ldots, y_n(x))\ \forall x \in I
				\end{equation*}			
			\item $f: G \subseteq \R^{n+1} \to \R^n$ mit
				\begin{equation*}
					f(x,y) = f(x, y_1, \ldots, y_n) = \begin{pmatrix}
						f_1(x, y_1, \ldots, y_n) \\
						\vdots \\
						f_n/(x, y_1, \ldots, y_n)
					\end{pmatrix}
				\end{equation*}
		\end{enumerate}
	\item AWP:
		\begin{equation*}
			\text{(AWP)} = \begin{cases}
				y' &= f(x,y) \\
				y(x_0) &= y_0
			\end{cases} \text{ mit }
			y_0 = \begin{pmatrix}
				y_1^{(0)} \\ \vdots \\ y_n^{(0)}
			\end{pmatrix}
		\end{equation*}
	\item Integration von Vektoren:
		Für $g:[a,b] \subseteq \R \rightarrow \R^n, g(x) = (g_1(x), \ldots, g_n(x))^T$ definieren wir (falls $g_1, \ldots, g_n$ int'bar sind):
		\begin{equation*}
		 \int_a^b g(x) \dx = \begin{pmatrix}
		 		\int_a^b g_1(x) \dx \\
		 		\vdots \\
		 		\int_a^b g_n(x) \dx \\
		 	\end{pmatrix}
		\end{equation*}
\end{enumerate}

\subsection{Voltera'sche Integralgleichung}
Sei $G \subseteq \R^{n+1}$ ein Gebiet, $f: G \to \R^n$ stetig und
\begin{equation*}
	\begin{pmatrix}
		x_0 \\ y_1^{(0)} \\ \vdots \\ y_n^{(0)}
	\end{pmatrix} = 
	\begin{pmatrix}
		x_0 \\ y_0
	\end{pmatrix}
	\in G
\end{equation*} 
dann ist $y: I \subseteq \R \to \R^n$ genau dann eine Lösung des AWP $y'=f(x,y), y(x_0)=y_0$, wenn gilt
\begin{equation*}
	y(x) = y_0 + \int_{x_0}^x f(t, y(t)) \dt
\end{equation*}

\subsection{Definition Lipschitz-Bedingung}
Sei $f: M \subseteq \R^{n+1} \to \R^n$. Dann erfüllt $f$ eine L-Bed. Mit $L>0$, wenn gilt:
\begin{equation*}
	\norm{f(x,y_1) - f(x, y_2)} < L \cdot \norm{y_1-y_2}\ \forall 
	\begin{pmatrix}
		x, y_1
	\end{pmatrix},
	\begin{pmatrix}
		x, y_2
	\end{pmatrix} \in M
\end{equation*}

\subsection{Bemerkung}
Welche Norm hier verwendet wird ist egal, denn es existiert ein $c_1, c_2$ mit
\begin{equation*}
	c_1 \norm{\cdot}_\infty \leq \norm{\cdot} \leq c_2 \norm{\cdot}
\end{equation*}

\subsection{Satz von Picard-Lindelöf}
Seien $r,s > 0; x_0 \in \R, y_0 = (y_1^{(0)}, \ldots, y_n^{(n)})^T \in \R^n$ und $M = \{
(x, y_1, \ldots, y_n)^T\in \R^n: x \in [x_0, x_0 + r], y_k \in [y_k^{(0)}-s, y_k^{(0)}+s]\}$
und $f: G \to \R^n$ stetig.

Falls $f$ auf $M$ eine L-Bed. erfüllt so exitiert auf $I = [x_0, x_0 + \alpha]$ mit $\alpha = \min \{r, \frac{s}{c} \}$
für
\begin{equation*}
	c := \max_{(x,y)^T \in M} \norm{f(x,y)}_\infty
\end{equation*}

\subsection{Satz von Peano}
Falls die L-Bed. im Satz von Picard-Lindelöf nicht erfüllt ist, alle anderen Vorraussetzungen aber gelten kann man auf
$I = [x_0, x_0 + \alpha]$ (mit $\alpha$ wie oben) trotzdem die Existenz einer Lösung zeigen, nicht aber deren Eindeutigkeit.

\subsection{Stabilität}
Analog gilt, falls $f$ eine L-Bed. erfüllt und eine Lösung existiert:
\begin{equation*}
	\norm{y_1(x) - y_2(x)}_\infty \leq (\norm{y_0 - \tilde{y_0}}_\infty c (x-x_0)) \exp{\left(L(x-x_0)\right)}
\end{equation*}
dabei ist $y_1$ Lösung von $y'=f_1(x,y), y(x_0)=y_0$ und $y'=f_2(x,y), y(x_0) = \overline{y_0}$

\section{Lineare DGL-Systeme 1. Ordnung}
\subsection{Definition}
Ein DGL System der Form
\begin{equation*}
	\begin{pmatrix}
		y_1'(x) \\ \vdots \\ y_n'(x)
	\end{pmatrix} = 
	\begin{pmatrix}
		a_{11}(x) & \cdots & a_{1n}(x) \\
		\vdots & \ddots & \vdots \\
		a_{n1}(x) & \cdots & a_{nn}(x)
	\end{pmatrix}
	\begin{pmatrix}
		y_1(x) \\ \vdots \\ y_n(x)
	\end{pmatrix} +
	\begin{pmatrix}
		b_1(x) \\ \vdots \\ b_n(x)
	\end{pmatrix}
\end{equation*}
oder in kurz:
\begin{equation*}
	y'(x) = A(x) y(x) + b(x)
\end{equation*}
mit stetigen Funktionen $a_{ij}: I \to \R, b_i:I \to \R\ \forall i,j \in \{1, \ldots, n\},\ I \subseteq \R$ ein Intervall heißt ein lineares DGL-System 1. Ordnung.

\subsection{Definition Frobenius-Norm}
Für $A \in \R^{m \times n}$ ist durch
\begin{equation*}
	\norm{A}_F = \sqrt{\sum_{i=1}^n \sum_{j=1}^n \abs{a_{ij}}^2}
\end{equation*}
die sogenannte Frobenius-Norm $\norm{\cdot}_F: \R^{m \times n} \rightarrow \R$ definiert.

\subsection{Matrixnorm und Vektornorm}
\begin{enumerate}[label= (\alph*)]
	\item $\norm{\cdot}_F$ ist eine Vektornorm auf dem Vektorraum $\R^{m \times n}$ (oder $\C^{m \times n}$)
	\item Die Matrix-Norm $\norm{\cdot}_F$ ist bezüglich der Vektornorm $\norm{\cdot}_2$ submultiplikativ, d.h. es gilt
		\begin{equation*}
			\norm{A \cdot x}_2 \leq \norm{A}_F \cdot \norm{x}_2
		\end{equation*}
	\item Bezüglich einer beliebigen Vektornorm auf $\R^n$ gilt:
		\begin{equation*}
			\norm{A x} \leq c_1 \norm{A x}_2 \leq \norm{A}_F \norm{x}_2 \leq c_2 \norm{A}_F \norm{x}
		\end{equation*}
\end{enumerate}

\subsection{Grenznorm}
Die sogenannte Grenznorm für eine Matrix-Norm wird bezüglich einer Vektornorm $\norm{\cdot}$ so definiert:
\begin{equation*}
	\norm{A} := \sup_{x \in \R^n \land x\neq \vec{0}} \frac{\norm{A x}}{\norm{x}} = \max_{\norm{x}=1} \norm{A x}
\end{equation*}
Daraus folgt:
\begin{equation*}
	\norm{A x} \leq \norm{A} \norm{x}
\end{equation*}
und für mindestens ein $x$ gilt $=$ (d.h die Abschätzung ist scharf).

Die Bezeichnung der Grenznorm wird von der Vektornorm übernommen. Es gilt also:
\begin{equation*}
	\norm{A}_p = \sup_{x \in \R^n \land x \neq \vec{0}} \frac{\norm{A x}_p}{\norm{x}_p}
\end{equation*}
die Grenznorm bezüglich $\norm{\cdot}_p$.

\subsubsection{Bemerkung}
Es gilt:
\begin{equation*}
	\norm{A}_2 \leq \norm{A}_F
\end{equation*}

\subsection{Lösungsmengen von linearen Gleichungssystemen}
\begin{enumerate}[label= (\alph*)]
	\item Die Lösungsmenge von $y' = A(x) y$ ist ein Unterraum des Vektorraums der stetigen Funktionen
	\item Die Lösungsmenge von $y' = A(x) y + b(x)$ ist ein affiner Unterraum des Vektorraums der stetigen Funktionen
\end{enumerate}

\subsection{Definition Fundamentalsystem}
Sei $I \subseteq \R$ ein nicht entartetes Intervall und $A: I \to \R^{n \times n}$ stetig
\begin{enumerate}[label= (\alph*)]
	\item Eine Basis des Lösungsraums von $y' = A(x) y$ heißt Fundamentalsystem (FS). Ist $y_1, \ldots, y_n$ so ein FS,
		dann heißt die Matrix 
		\begin{equation*}
			Y(x) = (y_1(x), \ldots, y_n())
		\end{equation*}
		die Fundamentalmatrix
	\item Für $y_1, \ldots, y_n: I \to \R^n$ heißt $W: I \to \R$ mit $W(x) = \det (Y(x))$ die Wronski-Determinante
		des Fundamentalsystems.
\end{enumerate}

\subsection{Definition Determinante}
Eine Funktion $\det: \R^{n \times n} \to \R$ heißt Determinante, wenn gilt
\begin{enumerate}[label= (\alph*)]
	\item Mit $I$ der Einheitsmatrix:
		\begin{equation*}
			\det(I) = 1
		\end{equation*}
	\item $\det$ ist linear in jeder Spalte, d.h. für $1\leq l \leq n$ gilt:
		\begin{equation*}
			\det(a_1 \ldots, a_{l-1}, \alpha x + \beta y, a_{l+1}, \ldots, a_n) =
			\alpha \det(a_1 \ldots, a_{l-1}, x, a_{l+1}, \ldots, a_n) + 
			\beta \det(a_1 \ldots, a_{l-1}, y, a_{l+1}, \ldots, a_n)
		\end{equation*}
	\item Spalten tauschen ändert Vorzeichen:
		\begin{equation*}
			\det(a_1, \ldots, a_i, \ldots, a_j, \ldots, a_n) =
			\det(a_1, \ldots, a_j, \ldots, a_i, \ldots, a_n)
		\end{equation*}
\end{enumerate}

\subsection{Entwicklungssatz von Laplace}
Sei $A \in \R^{n \times n}$ und bezeichne $A_{ij}$ die $(n-1)\times(n-1)$ Matrix, die aus $A$ durch Streichen
der $i$-ten Zeile und $j$-ten Spalte entsteht. Die Einträge von $A$ bezeichnen wir mit $A = (a_{ij})_{1 \leq i,j \leq n}$. Dann gilt:
\begin{enumerate}[label= (\alph*)]
	\item Für $j \in \{1, \ldots, n \}$ beliebig aber fest ist
		\begin{equation*}
			\det(A) = \sum_{i=1}^n a_{ij} \det{A_{ij}} {(-1)}^{i+j}
		\end{equation*}
	\item Für $i \in \{1, \ldots, n \}$ beliebig aber fest ist
		\begin{equation*}
			\det(A) = \sum_{j=1}^n a_{ij} \det{A_{ij}} {(-1)}^{i+j}
		\end{equation*}
\end{enumerate}

\subsection{Leibniz-Formel für Determinanten}
Sei $A \in \R^{n \times n}$ und bezeichne $S_n$ die Gruppe der Permutationen von
$\{1, \ldots, n\}$ und sei $\sgn(\sigma)$ definiert durch $\sgn: S_n \to \{-1, 1\}$:
\begin{equation*}
	\sgn{\sigma} = \begin{cases}
		1 & \text{ falls $\sigma$ durch eine gerade Anzahl Permutationen entsteht} \\
		-1 & \text{ sonst}
	\end{cases}
\end{equation*}
wobei eine Transposition einer paarweisen Vertauschung entspricht.

Dann gilt:
\begin{equation*}
	\det(A) = \det((a_{ij})_{1\leq  i,j \leq n}) = 
	\sum_{\sigma \in S_n} \sgn(\sigma) \prod_{k=1}^n a_{k\sigma(k)}
\end{equation*}

\subsection{Berechnung der Wronski-Determinante ohne bekanntes FS}
Für die Wronski-Determinante gilt (d.h. FS existiert, sonst ist Wronski-Determinante nicht
definiert):
\begin{enumerate}[label= (\alph*)]
	\item $W(x)$ kann durch eine lineare DGL 1. Ordnung bestimmt werden:
		\begin{equation*}
			W'(x) = \operatorname{spur}(A(x)) \cdot W(x)
		\end{equation*}
		mit
		\begin{equation*}
			\operatorname{spur}(A) = \sum_{i=1}^n a_{ii}
		\end{equation*}
	\item
		Durch Lösen der DGL folgt:
		\begin{equation*}
			W(x) = W(x_0) \cdot \exp\left(\int_{x_0}^x \operatorname{spur}(A(t)) \dt \right)
		\end{equation*}
\end{enumerate}

\subsubsection{Bemerkung}
Falls $y' = A(x) y$ eine Anfangsbedingung hat ist $W(x_0)$ durch die Anfangsbedinung bekannt, dadurch ist
$W(x)$ bekannt.


\subsection{Ableitung der Determinante}
Sei $I \subseteq \R$ ein nicht-entartetes Interval und $A(x)$ (komponentenweise) differentierbar auf
$I$, dann ist $\det(A(x))$ differentierbar und es gilt:
\begin{equation*}
	\ddx \det(A(x)) = \sum_{i=1}^n \det \begin{pmatrix}
		a_{11}(x) & \cdots & a_{1n}(x)\\
		& \vdots \\
		a_{i-1,1}(x) & \cdots & a_{i-1,n}(x)\\
		a'_{i1}(x) & \cdots & a'_{in}(x)\\
		a_{i+1,1}(x) & \cdots & a_{i+1,n}(x)\\
		& \vdots \\
		a_{n1}(x) & \cdots & a_{nn}(x)\\
	\end{pmatrix}
\end{equation*}


\subsection{Äquivalente Aussagen zu FSen und Wronski-Determinaten}
Sei $I \subseteq \R$ ein nicht entartetes Interval, $A: I \to \R^{n \times n}$ stetig.
Sind $y_1, \ldots, y_n$ Lösungen von $y' = A(x)  y$ und bezeichne $W(x) = \det(y_1(x), \ldots, y_n(x))$
dann sind folgende Aussagen äquivalent:
\begin{enumerate}[label= (\alph*)]
	\item $y_1, \ldots, y_n$ bilden ein FS
	\item $W(x) \neq 0\ \forall x \in I$
	\item $\exists x_0 \in I: W(x_0) \neq 0$
\end{enumerate}		

\subsection{Partikuläre Lösung aus Wronksi-Determinante}
Sei $I \subseteq \R$ ein nicht entartetes Intervall, $A: I \to \R^{n \times n}$ stetig und $b: I \to \R^n$
stetig, weiter sei $y_1, \ldots, y_n$ ein FS des homogenen Systems $y' = A(x) y$.

Dann ist:
\begin{equation*}
	y_p: I \to \R^n \text{ mit } y_p(x) = \sum_{k=1}^n y_k(x) \int_{x_0}^x \frac{W_k(t)}{W(t)} \dt
\end{equation*}
mit $x_0 \in I$ beliebig und 
\begin{equation*}
	W_k(x) = \det(y_1(x), \ldots, y_{k-1}(x), b(x), y_{k+1}(x), \ldots, y_n(x))
\end{equation*}
eine Lösung des inhomogenen Systems
\begin{equation*}
	y'(x) = A(x) y(x) + b(x)
\end{equation*}

\section{Lineare DGL-Systeme 1. Ordnung mit konstanten Koeffizienten}
Für $A \in \R^{n \times n}$ betrachtet man $y' = A y + b(x)$
bzw. $y' = A y$. Ein FS von $y' = A y$ liefert eine partikuläre Lösung von
$y' = A y + b(x)$.

\subsection{Definition Eigenwerte und Eigenvektoren}
Sei $A \in \K^{n\times n}$ (mit $\K = \R$ oder $\K = \C$), dann heißt ein $\lambda \in \K$
Eigenwert von $A$, wenn ein $v \in \K^n\backslash\{\vec{0}\}$ existiert mit
\begin{equation*}
	A v = \lambda v
\end{equation*}

\subsubsection{Bemerkung}
\begin{enumerate}[label= (\alph*)]
	\item Ein Eigenvektor $v$ zum Eigenwert $\lambda$ existiert genau dann, wenn
		\begin{equation*}
			p_A(\lambda) := \det(A - \lambda - I) = 0
		\end{equation*}
		ist.
	\item Offensichtlich gilt: Ist $v$ ein Eigenvektor zum Eigenwert $\lambda$ so ist auch 
		$\alpha v$ ein Eigenvektor zu $\lambda$.
	\item Offensichtlich ist $y = v \cdot \exp{\lambda}$ eine Lösung der homogenen DGL $y' = A y$
		wenn $v$ eine Eigenvektor von $A$ und $\lambda$ ein zugehöriger Eigenwert ist.
\end{enumerate}

\subsection{Algebraische und Geometrische Vielfachheit}
Ist $\lambda$ ein Eigenwert von $A \in \K^{n \times n}$, dann ist
\begin{enumerate}[label= (\alph*)]
	\item Die Algebraische Vielfachheit von $\lambda$ die Ordnung der Nullstelle von $p_A(\lambda)$
	\item Die Geometrische Vielfachheit von $\lambda$ die Dimension von $\Kern(A-\lambda I)$, also die
		Anzahl der linear Unabhängigen Lösungen von $A - \lambda I = \vec{0}$.
\end{enumerate}

\subsection{Diagonalisierbarkeit}
Falls zu einer Matrix $A \in \K^{n \times n}$ eine reguläre Matrix $V \in \K^{n \times n}$ existiert mit
\begin{equation*}
	V^{-1} A V = \operatorname{diag}(\lambda_1, \ldots, \lambda_n) = 
	\begin{pmatrix}
		\lambda_1 & 0 & \cdots & 0 & 0 \\
		0 & \lambda_2 & \cdots & 0 & 0 \\
		\vdots & \vdots & \ddots & \vdots \\
		0 & 0 & \cdots & \lambda_{n-1} & 0\\
		0 & 0 & \cdots & 0 & \lambda{n}
	\end{pmatrix}
\end{equation*}
so heißt $A$ diagonalisierbar.

\subsubsection{Bemerkung}
\begin{enumerate}[label= (\alph*)]
	\item Es gilt:
		\begin{eqnarray*}
			V^{-1} A V &=& \operatorname{diag}(\lambda_1, \ldots, \lambda_n)\\
			\Leftrightarrow A V &=& \operatorname{diag}(\lambda_1, \ldots, \lambda_n) V \\
			\Leftrightarrow (A  \cdot v_1, \ldots, A \cdot v_n) &=& (\lambda_1 v_1, \ldots, \lambda_n v_n)
			\Leftrightarrow A v_k = \lambda_k v_k\ \forall k \in \{1, \ldots, n\}
		\end{eqnarray*}
		d.h $V$ besteht aus den Eigenvektoren von $A$ und die Diagonalmatrix aus den Zugehörigen Eigenwerten.
	\item Ist $A$ diagonalisierbar, dann gilt:
		\begin{eqnarray*}
			A^l = (V D V^{-1}) (V D V^{-1}) \cdots (V D V^{-1}) = V D^l V^{-1} = V 
			\operatorname{diag}(\lambda_1^l, \ldots, \lambda_n^l) V^{-1}
		\end{eqnarray*}
	\item So ein $V$ existiert nur wenn $n$-linear Unabhängige Eigenvektoren existieren, da die Matrix $V$ sonst nicht
		invertierbar ist.
	\item Selbst wenn $A$ eine reele Matrix ist sind die Eigenwerte und -vektoren im Allgemeinen Komplex
	\item Bei einer Matrix mit reelen Koeffizienten gilt stets $\lambda$ ist Eigenwert $\Rightarrow \overline{\lambda}$
		ist ebenfalls Eigenwert.
	\item Das heißt aus dem FS einer Reelen Matrix lässt sich stets ein reeles Fundamentalsystem konstruieren.
\end{enumerate}

\subsection{Submultiplikativität von $\norm{\cdot}_F$}
Für $A,B \in \C^{n \times n}$ gilt
\begin{eqnarray*}
	\norm{A B}_F \leq \norm{A}_F \norm{B}_F
\end{eqnarray*}
mit $\norm{A}_F = \sum_{i=1}^n \sum_{j=1}^n \sqrt{ \abs{a_{ij}}^2}$

\subsubsection{Bemerkung}
Es gilt also auch, dass
\begin{eqnarray*}
 	\norm{A^k}_F \leq \norm{A}_F^k
\end{eqnarray*}

\subsection{Folgenkonvergenz für Matrizen}
Sei ${(A_k)}_{k=1}^\infty$ eine Folge in $\C^{n \times n}$, dann konvergiert die Folge gegen $A \in \C^{n \times n}$,
wenn gilt:
\begin{eqnarray*}
	\forall \varepsilon > 0: \exists k(\varepsilon): \norm{A_k - A}_F < \varepsilon\ \forall k \geq k(\varepsilon)
\end{eqnarray*}

\subsubsection{Bemerkung}
\begin{enumerate}[label= (\alph*)]
	\item Da $\C^{n \times n}$ ein endlicher Vektorraum ist könnte man eine beliebige Matrix-Norm wählen
	\item In $\C^{n \times n}$ konvergiert jede Cauchy-Folge
	\item Für eine Reihe $\sum_{k=0}^\infty A_k$ definiert man die Konvergenz über die Konvergenz der Partialsummen
		$B_l := \sum_{k=0}^l A_k$
\end{enumerate}

\subsection{Definition Matrix-Exponentialfunktion}
Für $A \in \C^{n \times n}$ definieren wir die Matrix Exponentialfunktion durch:
\begin{eqnarray*}
	\exp: \C^{n \times n} \to \C^{n \times n}, A \mapsto \exp(A) = \sum_{k=0}^\infty \frac{A^k}{k!}
\end{eqnarray*}

\subsubsection{Bemerkung}
$e^A = \exp(A)$ lässt sich leicht ausrechnen, wenn $A$ diagonalierbar ist.

\subsection{Rechenregeln Matrix-Exponentialfunktion}
Es gilt:
\begin{enumerate}[label= (\alph*)]
	\item $e^{A+B} = e^A + e^B$ für alle $A,B \in \C^{n \times n}$
	\item ${(e^A)}^{-1} = e^{-A}$ für alle $A \in \C^{n \times n}$
		d.h. $e^A$ ist stets invertierbar. 
\end{enumerate}

\subsection{Zusammenhang Matrix Exponentialfunktion und FS}
Sei $A \in \R^{n \times n}$ dann ist $Y(x) = \exp{(x A)}$ ein FS von $y' = Ay$